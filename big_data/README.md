# 数据研发相关

## ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `数据库`

### [范式](https://zhuanlan.zhihu.com/p/63146817

1NF 属性不可分，确保每列保持原子性（地址中拆分出城市）

2NF 每个非主属性完全函数依赖于键码。可以通过分解来满足。(确保表中的每列都和主键相关)
一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。

3NF 非主属性不传递函数依赖于键码。(确保每列都和主键列直接相关,而不是间接相关)

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `事务ACID`

事务是作为单个逻辑执行的一组操作，要么全成功，要么全失败。

Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。
事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。

Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。

Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。

Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `NoSQL`

非关系数据库，分类有：键值(Key-Value)存储数据库，列存储数据库，列存储数据库，图形(Graph)数据库

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `分布式事务`

分布式事务用于在分布式系统中保证不同节点之间的数据一致性。分布式事务的实现有很多种，具有代表性的是两阶段提交（2PC）。通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。

1 准备阶段：协调者询问参与者事务是否执行成功，参与者发回事务执行结果。询问可以看成一种投票，需要参与者都同意才能执行。

2 提交阶段：如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。
在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `CAP定理`

一致性(Consistency) 可用性(Availability) 分隔容忍(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作)

一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `事务的酸碱性？ACID酸，碱：BASE`

BASE:与ACID是RDBMS强一致性的四个要求对应，BASE是NoSQL通常对可用性及一致性的弱要求原则，它们的意思分别是，BASE：Basically Available（基本可用）, 
Soft-state（软状态/柔性事务。 "Soft state" 可以理解为"无连接"的）, Eventually Consistent（最终一致性）。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `事务隔离级别，按照性能排序`

未提交读（READ UNCOMMITTED）提交读（READ COMMITTED）可重复读（REPEATABLE READ）可串行化（SERIALIZABLE）

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `存储过程`

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `聚簇索引和非聚簇索引的区别?`

1.对于非聚簇索引表来说（右图），表数据和索引是分成两部分存储的，主键索引和二级索引存储上没有任何区别。使用的是B+树作为索引的存储结构，所有的节点都是索引，叶子节点存储的是索引+索引对应的记录的数据。

2.对于聚簇索引表来说（左图），表数据是和主键一起存储的，主键索引的叶结点存储行数据(包含了主键值)，二级索引的叶结点存储行的主键值。使用的是B+树作为索引的存储结构，非叶子节点都是索引关键字，但非叶子节点中的关键字中不存储对应记录的具体内容或内容地址。叶子节点上的数据是主键与具体记录(数据内容)。

聚簇优点：当你需要取出一定范围内的数据时，用聚簇索引也比用非聚簇索引好。
聚簇索引查找目标数据时理论上比非聚簇索引要快，因为非聚簇索引定位到对应主键时还要多一次目标记录寻址,即多一次I/O。


聚簇缺点：1，插入速度严重依赖于插入顺序。2.更新主键的代价很高，因为将会导致被更新的行移动。
3.二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。
4.采用聚簇索引插入新值比采用非聚簇索引插入新值的速度要慢很多

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `红黑树`

自平衡的二叉查找树，有序（有序输出比较快），红黑树通过规则设置保证了查找和删除的时间复杂度都是O(logn)。是弱平衡的二叉树，左右子树高度差可能达到一杯。
三种自平衡操作：左旋、右旋和变色。红黑树多用于内存中查询。

性质1：每个节点要么是黑色，要么是红色。
性质2：根节点是黑色。
性质3：每个叶子节点（NIL）是黑色。
性质4：每个红色结点的两个子结点一定都是黑色。
性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `B树`

B树平衡多路查找树（m阶）：每个节点最多有m-1个关键字（可以存有的键值对）。根节点最少可以只有1个关键字。
非根节点至少有m/2个关键字。每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。
所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同。每个节点都存有索引和数据，也就是对应的key和value。
M阶树，插入时当关键字大于M-1的时候要进行节点拆分。
删除时候当父亲节点关键字小于2，从右侧选取放到父。从父挪一个到当前位置。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `B+树`

B+树有两种类型的节点：内部节点（也称索引结点）和叶子结点。内部节点就是非叶子节点，内部节点不存储数据，只存储索引，数据都存储在叶子节点。
根节点至少一个元素，非根节点元素范围：m/2 <= k <= m-1。
内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。
每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。父节点存有右孩子的第一个元素的索引。


### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `红黑树、B+树和B树区别`

B树的优点：对于在内部节点的数据，可直接得到，不必根据叶子节点来定位。

B+树的优点：多用于外存中，磁盘读写代价低（索引可以都放在一个block中，硬盘寻址次数和树高成正比，寻址次数降低）。
查询效率稳定。叶子节点之间通过指针来连接，遍历所有数据更方便（B树需要中序遍历）。

红黑树多用在内部排序，即全放在内存中的。比B树高更高。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `mysql的哈希索引和B+树索引`

哈希无序，无法排序和模糊查找。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `内连接，左连接，右连接，全连接`

内连接只两边能连接在一起的数据返回，左连接返回左表数据并把右表关联的数据也连接上返回（一对多情况下右表中有多个结果也都返回）
全连接两边数据都展示，如果没有连接就是空值

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `唯一索引，索引的数据结构`

数据量大，减少服务器扫描数据量。帮助排序和分组（避免临时空间），随机I/O变为顺序I/O（B+树）

普通索引加快速度，唯一索引确定某个列的值是独一无二的。mysql插入时候会检查。通常不是用来提高速度是用来避免重复。主键索引也可以保证唯一

B+树和哈希的数据结构

## ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `概念问题`

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `星型模型和雪花型模型比较`

星型模是一种多维的数据关系，它由一个事实表和一组维表组成。每个维表都有一个维作为主键，所有这些维的主键组合成事实表的主键。
因为数据的冗余所以很多统计查询不需要做外部的连接，因此一般情况下效率比雪花型模型要高。对OLAP的分析比较方便。
星型模型的设计方式主要带来的好处是能够提升查询效率

当有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上时，图像就像多个雪花连接在一起，就是雪花模型。雪花模型是对星型模型的扩展。
雪花模型更加符合数据库范式，设计方式比较正规，减少数据冗余，但是在分析数据的时候，操作比较复杂。性能并不一定比星型模型高。

数据仓库大多数时候是比较适合使用星型模型构建底层数据Hive表，通过大量的冗余来提升查询效率，星型模型对OLAP的分析引擎支持比较友好。
雪花模型在关系型数据库中如MySQL，Oracle中非常常见，尤其像电商的数据库表。
实际使用的具体设计的时候，可以考虑是不是能结合两者的优点参与设计，以此达到设计的最优化目的。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `数据仓库、数据湖、数据中台`

数据仓库(Data Warehouse)是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化的（Time Variant）数据集合，
用于支持管理决策和信息的全局共享。

数据湖（Data Lake）是一个存储企业的各种各样原始数据的大型仓库，其中的数据可供存取、处理、分析及传输。
数据湖是以其自然格式存储的数据的系统或存储库，通常是对象blob或文件。数据湖通常是企业所有数据的单一存储，
包括源系统数据的原始副本，以及用于报告、可视化、分析和机器学习等任务的转换数据。数据湖可以包括来自关系数据库（行和列）的结构化数据，
半结构化数据（CSV，日志，XML，JSON），非结构化数据（电子邮件，文档，PDF）和二进制数据（图像，音频，视频）。

数据中台是指通过企业内外部多源异构的数据采集、治理、建模、分析，应用，使数据对内优化管理提高业务，对外可以数据合作价值释放，
成为企业数据资产管理中枢。数据中台建立后，会形成数据API，为企业和客户提供高效各种数据服务。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `数据仓库分层`

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `sybase IQ列式数据库和行式数据库区别`

列式数据库优点：速度快，适合大数据，实时加载数据仅限于增加（删除和更新需要解压缩Block 然后计算然后重新压缩储存），高效的压缩率，不仅节省储存空间也节省计算内存和CPU。
非常适合做聚合操作。定期批量更新（一天三次左右）

列式缺点：不适合小数据，不适合随机更新，不适合做删除和实时操作的。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `数据倾斜怎么办？`

数据倾斜产生的现象是hive运算卡在99.9%。OOM错误，一些executor使用率低。原因是key分布不均匀导致的，Shuffle动作中，相同key的值就会拉到一个或几个节点上，就容易发生单点问题。

mapjoin方法（关联操作中有一张小表，将小表直接读入内存，在map阶段直接拿另外一张表和内存中的表做计算，计算结果给reduce，提高了reduce的效率）

Hive参数调优：

set hive.map.aggr=true；在map中会做部分聚集操作，效率更高但需要更多的内存。

set hive.groupby.skewindata=true;数据倾斜时负载均衡，当选项设定为true，生成的查询计划会有两个MRJob。

第一个MRjob，Map的输出结果集合会随机分布到Reduce中，每个Reduce（相同key可能会发到不同reduce中）做部分聚合操作
第二个MRjob，再根据key分到不同reduce中

先group操作把key进行一次reduce，然后在进行count或者distinct count

从数据角度：在key上修改，aaa（大量数据的）加上后缀氛围1，2，3，4，5等，第一次计算后恢复在第二次计算。
对不均匀的数据单独计算（如北京数据非常多，单独计算后和其他城市合并），使用hash将可以将key打散，然后再汇总。数据预处理

## ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Hadoop`
> MR，HDFS等基本概念，面试常见题型

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `HDFS基本结构`

分布式文件系统HDFS是大数据的存储，block块默认最多可以存储128M

HDFS集群包括，NameNode和DataNode以及Secondary Namenode。NameNode负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。
DataNode 负责管理用户的文件数据块，每一个数据块都可以在多个datanode上存储多个副本。
Secondary NameNode用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。最主要作用是辅助namenode管理元数据信息

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `HDFS优缺点`

优点：1，高容错性。多个副本,切丢失一个后自动恢复。2，适合批处理，通过移动计算而不是移动数据，把数据位置暴露给计算框架。
3，适合大数据处理，可以处理GB,TB,PB级数据，可以处理百万规模以上的文件数量和10K节点的规模。4，流式数据访问，一次写入，多次读取，不能修改，只能追加。一致性。
5，可构建在廉价机器上

缺点：1，不适合低延时数据访问；2，无法高效的对大量小文件进行存储。3，并发写入、文件随机修改，一个文件只能有一个写，不允许多个线程同时写。
仅支持数据 append（追加），不支持文件的随机修改。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `MR是什么`

是大数据的计算

MapReduce流程：input->Splitting->Mapping->Shuffling->Reducing-> result

Hadoop计算框架Shuffle处于map和reduce阶段之间。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `MR编程流程模型`

map两步：1，设置inputFormat类，将我们的数据切分成key，value对，输入到第二步。
2，自定义map逻辑，处理我们第一步的输入数据，然后转换成新的key，value对进行输出

shuffle四步：3，对输出的key，value对进行分区。相同key的数据发送到同一个reduce里面去，相同key合并，value形成一个集合。
4，对不同分区的数据按照相同的key进行排序。5，对分组后的数据进行规约(combine操作)，降低数据的网络拷贝（可选步骤）
6，排序后分组，相同key的value放到同一个集合。

reduce两步：1，对多个map的任务进行合并，排序，写reduce函数自己的逻辑，对输出key value合并处理转换新的key，value输出。
2，设置outputformat将输出的key，value对数据进行保存到文件中

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `wordcount讲解`

1读取数据，生成key，value（word， 1）2，按照key排序。3，合并（key，value1，value2。。。）4，汇聚结果输出key，value1+value2+value3

## ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Hive`
> 基本概念，面试常见题型

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `什么是和Hive`

Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。其本质是将SQL转换为MapReduce的任务进行运算，
底层由HDFS来提供数据的存储，说白了hive可以理解为一个将SQL转换为MapReduce的任务的工具，甚至更进一步可以说hive就是一个MapReduce的客户端

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `与数据库的区别`

Hive 具有 SQL 数据库的外表，但应用场景完全不同。Hive 只适合用来做海量离线数据统计分析，也就是数据仓库。Hive主要是批量操作，执行延迟高。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Hive的优缺点`

优点：1，操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）。
2，避免了去写MapReduce，减少开发人员的学习成本。
3，Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。

缺点：1，Hive 的查询延迟很严重

## ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Spark`
> 基本概念，面试常见题型

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Spark为什么比MR更快`

MapReduce通常需要将计算的中间结果写入磁盘，然后还要读取磁盘，从而导致了频繁的磁盘IO。
Spark则不需要将计算的中间结果写入磁盘，这得益于Spark的RDD（弹性分布式数据集，很强大）和DAG（有向无环图），
其中DAG记录了job的stage以及在job执行过程中父RDD和子RDD之间的依赖关系。中间结果能够以RDD的形式存放在内存中，且能够从DAG中恢复，大大减少了磁盘IO。

MapReduce在Shuffle时需要花费大量时间进行排序，排序在MapReduce的Shuffle中似乎是不可避免的；
Spark在Shuffle时则只有部分场景才需要排序，支持基于Hash的分布式聚合，更加省时；

MapReduce采用了多进程模型，多进程模型的好处是便于细粒度控制每个任务占用的资源，但每次任务的启动都会消耗一定的启动时间。
Spark则是通过复用线程池中的线程来减少启动、关闭task所需要的开销。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `处理spark oom`

大约有两个情况：1、map执行内存溢出.2、shuffle后内存溢出

map执行中内存溢出代表了所有map类型的操作。包括：flatMap，filter，mapPatitions等。
通过减少每个task的大小来减少Executor内存中的数量，具体做法是在调用map操作前先调用repartition方法，增大分区数来减少每个分区的大小，再传入map中进行操作。

shuffle后内存溢出的shuffle操作包括join，reduceByKey，repartition等操作。
shuffle内存溢出的情况可以说都是shuffle后，shuffle会产生数据倾斜，少数的key内存非常的大，它们都在同一个Executor中计算，导致运算量加大甚至会产生OOM。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `spark的rdd特性`

弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合.
Dataset: 就是一个集合，存储很多数据.
Distributed：它内部的元素进行了分布式存储，方便于后期进行分布式计算.
Resilient： 表示弹性，rdd的数据是可以保存在内存或者是磁盘中.

五大属性：1，一个分区（Partition）列表，数据集的基本组成单位。一个rdd有很多分区（包含了该rdd的部分数据）
spark中任务是以task线程的方式运行， 一个分区就对应一个task线程。
2，一个计算每个分区的函数。Spark中RDD的计算是以分区为单位的，每个RDD都会实现compute计算函数以达到这个目的.
3，一个rdd会依赖于其他多个rdd。这里就涉及到rdd与rdd之间的依赖关系，spark任务的容错机制就是根据这个特性（血统）而来。
4，一个Partitioner，即RDD的分区函数（可选项）
5，一个列表，存储每个Partition的优先位置(可选项)

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `spark和flink`

flink提供事件级处理，也称为实时流。Spark是迷你批处理。这种方法被称为接近实时。

## ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `SQL题`

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `窗口函数`

窗口函数的基本语法如下：<窗口函数> over (partition by <用于分组的列名> order by <用于排序的列名>)

排序函数：

- rank() 1，1，1，4，5，
- dense_rank() 1，1，1，2，3，
- row_number() 1，2，3，4，5，

聚合窗口函数：SUM、AVG、MAX、MIN。都是根据order by列名进行排序，对当前所在行之上的进行聚合。

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `聚合操作（统计连续10天在线超过1000人的城市）`

user_id, city, date

```sql
select b.city
from 
(select a.city, count(distinct a.user_id) as count, a.date - ROW_NUMBER() OVER(PARTITION BY a.city ORDER BY a.date) AS temp 
from
(select t.*
from user_data t
order by t.user_id, t.date
) a
gouryby b.city
having count>=1000
) b
where b.temp >=10


```

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `直播统计`

1、统计每天每个直播间的访客数、每天最大访客数的直播间
2、查找至少连续观看3天的用户ID 及出现直播间

```sql

select LiveID,count(UserID) as visitnum 
FROM table
Group By LiveID 
Order By visitnum DESC(ASC)

select max(visitnum) as maxvisit,LiveID 
From previous table

SELECT *
from (select Date - ROW_NUMBER() OVER(ORDER BY DATE ASC) AS times,userid, liveid
FROM table
Group By userid, liveid) as T
where times>3


```

### ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `如何删除两条一模一样的数据中的一条`

创建视图在视图中删除，视图中没有聚合的操作是可以删除的，删除原表数据。

name, value
```sql
DELETE FROM
(SELECT ROW_NUMBER() OVER(PARTITION BY name, value ORDER BY(SELECT 1)) AS no,
name, value FROM test_table
) AS T WHERE T.no != 1
```

## 引用资源

- [大数据面试题总结](https://www.jianshu.com/p/045a576abeea)

- [阿里，头条，美团，快手大数据开发岗面试总结](https://mp.weixin.qq.com/s/SHH64TJvx5kpIl-3cMzypw)
