# 数据研发相关

## 数据库

### [范式](https://zhuanlan.zhihu.com/p/63146817)

1NF 属性不可分，确保每列保持原子性（地址中拆分出城市）

2NF 每个非主属性完全函数依赖于键码。可以通过分解来满足。(确保表中的每列都和主键相关)
一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。

3NF 非主属性不传递函数依赖于键码。(确保每列都和主键列直接相关,而不是间接相关)

### 事务ACID

事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。
原子性（Atomicity）一致性（Consistency）隔离性（Isolation）一个事务最终提交前，其他事务不可见。持久性（Durability）

### 事务隔离级别，按照性能排序

未提交读（READ UNCOMMITTED）提交读（READ COMMITTED）可重复读（REPEATABLE READ）可串行化（SERIALIZABLE）

### 存储过程

### 红黑树

自平衡的二叉查找树，三种自平衡操作：左旋、右旋和变色。红黑树多用于内存中查询。

性质1：每个节点要么是黑色，要么是红色。
性质2：根节点是黑色。
性质3：每个叶子节点（NIL）是黑色。
性质4：每个红色结点的两个子结点一定都是黑色。
性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。

### B+树和B树区别

B树平衡多路查找树：每个节点最多有m-1个关键字（可以存有的键值对）。根节点最少可以只有1个关键字。
非根节点至少有m/2个关键字。每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。
所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同。每个节点都存有索引和数据，也就是对应的key和value。
N阶树，插入时当关键字大于N-1的时候要进行节点拆分。
删除时候当父亲节点关键字小于2，从右侧选取放到父。从父挪一个到当前位置。

B+树有两种类型的节点：内部结点（也称索引结点）和叶子结点。内部节点就是非叶子节点，内部节点不存储数据，只存储索引，数据都存储在叶子节点。
内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。
每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。父节点存有右孩子的第一个元素的索引。
B+树多用于外存中，磁盘读写代价低（索引可以都放在一个block中）。查询效率稳定。遍历所有数据更方便（B树需要中序遍历）。B+ 树有更低的树高

### mysql的哈希索引和B+树索引

哈希无序，无法排序和模糊查找。

### 内连接，左连接，右连接，全连接

内连接只两边能连接在一起的数据返回，左连接返回左表数据并把右表关联的数据也连接上返回（一对多情况下右表中有多个结果也都返回）
全连接两边数据都展示，如果没有连接就是空值

### 唯一索引，索引的数据结构

数据量大，减少服务器扫描数据量。帮助排序和分组（避免临时空间），随机I/O变为顺序I/O（B+树）

普通索引加快速度，唯一索引确定某个列的值是独一无二的。mysql插入时候会检查。通常不是用来提高速度是用来避免重复。主键索引也可以保证唯一

B+树和哈希的数据结构

## 概念问题

### 星型模型和雪花型模型比较

### 数据仓库、数据湖、数据中台

数据仓库(Data Warehouse)是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化的（Time Variant）数据集合，
用于支持管理决策和信息的全局共享。

数据湖（Data Lake）是一个存储企业的各种各样原始数据的大型仓库，其中的数据可供存取、处理、分析及传输。
数据湖是以其自然格式存储的数据的系统或存储库，通常是对象blob或文件。数据湖通常是企业所有数据的单一存储，
包括源系统数据的原始副本，以及用于报告、可视化、分析和机器学习等任务的转换数据。数据湖可以包括来自关系数据库（行和列）的结构化数据，
半结构化数据（CSV，日志，XML，JSON），非结构化数据（电子邮件，文档，PDF）和二进制数据（图像，音频，视频）。

数据中台是指通过企业内外部多源异构的数据采集、治理、建模、分析，应用，使数据对内优化管理提高业务，对外可以数据合作价值释放，
成为企业数据资产管理中枢。数据中台建立后，会形成数据API，为企业和客户提供高效各种数据服务。

### sybase IQ列式数据库和行式数据库区别

列式数据库优点：速度快，适合大数据，实时加载数据仅限于增加（删除和更新需要解压缩Block 然后计算然后重新压缩储存），高效的压缩率，不仅节省储存空间也节省计算内存和CPU。
非常适合做聚合操作。定期批量更新（一天三次左右）

列式缺点：不适合小数据，不适合随机更新，不适合做删除和实时操作的。

### 数据倾斜怎么办？

Hive数据运算卡在99.9%，SparkStreaming做实时算法时候，可能会出现OOM，但其他的executor使用率低。关键是数据量大。
产生的原因是Shuffle动作中，相同key的值就会拉到一个或几个节点上，就容易发生单点问题。就是数据的key 的分化严重不均

Hadoop：reduce卡住，container报错OOM，出现任务被kill等诡异情况。Hive经常出现在sql的group by上。
mapjoin方法（关联操作中有一张小表，将小表直接读入内存，在map阶段直接拿另外一张表和内存中的表做计算，计算结果给reduce，提高了reduce的效率）

Hive参数调优：

set hive.map.aggr=true；在map中会做部分聚集操作，效率更高但需要更多的内存。

set hive.groupby.skewindata=true;数据倾斜时负载均衡，当选项设定为true，生成的查询计划会有两个MRJob。

第一个MRjob，Map的输出结果集合会随机分布到Reduce中，每个Reduce（相同key可能会发到不同reduce中）做部分聚合操作
第二个MRjob，再根据key分到不同reduce中

在key上修改，aaa（大量数据的）加上后缀氛围1，2，3，4，5等，第一次计算后恢复在第二次计算。

先group操作把key进行一次reduce，然后在进行count或者distinct count

Spark：Streaming和sql上。Executor执行时间特别久，整体任务卡在某个阶段不能结束。streaming中一些类似sql的join、group操作会经常出现数据倾斜。
mapjoin方法（同上）

数据角度：异常数据直接删除（例如ip为0），对不均匀的数据单独计算（如北京数据非常多，单独计算后和其他城市合并），使用hash将可以将key打散，然后再汇总。数据预处理


## Hadoop
> MR，HDFS等基本概念，面试常见题型

### MR编程流程模型

map两步：1，数据切分成key，value。2，自定义逻辑转换成新的key，value。

shuffle四步：3，按key分区，发送不懂reduce。4，不同分局按key排序。5，进行数据规约合并操作（可选）6，排序后分组，相同key放到同一个集合。

reduce两步：1，对map输出key value合并处理转换新的keyvalue。2，输出的值保存到文件中。

### wordcount讲解

1读取数据，生成key，value（word， 1）2，按照key排序。3，合并（key，value1，value2。。。）4，汇聚结果输出key，value1+value2+value3

## Hive
> 基本概念，面试常见题型

## Spark
> 基本概念，面试常见题型

## SQL题

## 聚合操作（统计连续10天在线超过1000人的城市）

### 直播统计

1、统计每天每个直播间的访客数、每天最大访客数的直播间
2、查找至少连续观看3天的用户ID 及出现直播间

```sql

select LiveID,count(UserID) as visitnum 
FROM table
Gourp By LiveID 
Order By visitnum DESC(ASC)

select max(visitnum) as maxvisit,LiveID 
From previous table

SELECT *
from (select Date - ROW_NUMBER() OVER(ORDER BY DATE ASC) AS times,userid, liveid
FROM table
Group By userid, liveid) as T
where times>3


```

## 引用资源

- [大数据面试题总结](https://www.jianshu.com/p/045a576abeea)

- [阿里，头条，美团，快手大数据开发岗面试总结](https://mp.weixin.qq.com/s/SHH64TJvx5kpIl-3cMzypw)
